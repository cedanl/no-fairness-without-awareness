---
title: "Transparante Kansengelijkheidsanalyse"
subtitle: "`r params$subtitle`"
params:
  subtitle: "Opleiding Onbekend"
  temp_dir: "temp"
  work_dir: "."
format:
  pdf:
    documentclass: article
    geometry: margin=0.75in
    fontsize: 11pt
    papersize: A4
    toc: false
    toc-depth: 2
    number-sections: false
    keep-tex: false
    include-in-header:
      text: |
        \usepackage{setspace}
        \setstretch{1.05}
        \usepackage{parskip}
        \setlength{\parskip}{0.6em}
        \usepackage{titlesec}
        \usepackage{xcolor}
        % Section formatting
        \titleformat{\section}
          {\Large\bfseries\color[gray]{0.2}}
          {\thesection}{1em}{}
          [\vspace{0.3em}\hrule\vspace{0.3em}]
        \titlespacing*{\section}{0pt}{1.2em}{0.8em}
        % Subsection formatting
        \titleformat{\subsection}
          {\large\bfseries}
          {\thesubsection}{0.8em}{}
        \titlespacing*{\subsection}{0pt}{0.9em}{0.5em}
        % Subsubsection formatting
        \titleformat{\subsubsection}
          {\normalsize\bfseries}
          {\thesubsubsection}{0.6em}{}
        \titlespacing*{\subsubsection}{0pt}{0.6em}{0.3em}
execute:
  cache: false
---

```{r}
#| label: setup
#| echo: false
#| include: false

# Set knitr's root directory to the user's working directory
# This ensures all paths are resolved relative to where the user is working
knitr::opts_knit$set(root.dir = params$work_dir)
```

# Hoofdbevindingen

```{r}
#| echo: false
#| results: asis

# Load conclusions
temp_path <- params$temp_dir
conclusions_list <- readRDS(file.path(temp_path, "conclusions_list.rds"))

# Create executive summary
has_bias <- any(sapply(conclusions_list, function(x) !grepl("geen sprake van bias", tolower(x))))

if (has_bias) {
  cat("**Er is bias geconstateerd** in één of meer onderzochte variabelen.\n\n")
  cat("Dit rapport identificeert verschillen in studiesucces tussen groepen studenten op basis van persoonskenmerken. Deze bevindingen vereisen nadere analyse en mogelijke interventies om kansengelijkheid te bevorderen.\n")
} else {
  cat("**Geen significante bias geconstateerd** in de onderzochte variabelen.\n\n")
  cat("De analyse toont geen substantiële verschillen in studiesucces tussen groepen op basis van de onderzochte persoonskenmerken.\n")
}
```

## Kansengelijkheid per variabele

```{r}
#| echo: false
#| results: asis

temp_dir <- params$temp_dir

for (var_name in names(conclusions_list)) {
  var_title <- stringr::str_to_title(var_name)
  cat("**", var_title, "**", ":", sep = "")
  cat(conclusions_list[[var_name]], "\n\n")
}
```

\newpage 

# Inleiding

Het lectoraat Learning Technology & Analytics (LTA) van De Haagse Hogeschool heeft tot doel kansengelijkheid voor studenten te verhogen met behulp van learning analytics en inzet van learning technology.

Het lectoraat heeft een onderzoeksmethode ontwikkeld om te kunnen analyseren of er sprake is van bias in studiedata in relatie tot het succes van studenten, wat een indicatie kan zijn van een gebrek aan kansengelijkheid. Deze methode gebruikt prognosemodellen op basis van machine learning. Een prognosemodel is dus niet een doel op zich, maar het instrument voor een analyse van kansengelijkheid, ook wel een *fairness* analyse genoemd.

Over deze methode heeft de lector, Dr. Theo Bakker, zijn intreerede uitgesproken op 21 november 2024, getiteld: '[No Fairness without Awareness. Toegepast onderzoek naar kansengelijkheid in het hoger onderwijs. Intreerede lectoraat Learning Technology & Analytics.](https://zenodo.org/records/14204674)' [@Bakker.2024-intreerede].

Zie voor een verdere toelichting op het gehele onderzoeksprogramma: '[No Fairness without Awareness](https://www.dehaagsehogeschool.nl/onderzoek/kenniscentra/no-fairness-without-awareness)'.

## Wat is een kansengelijkheidsanalyse?

Kansengelijkheid betekent dat alle studenten gelijke kansen hebben om succesvol te zijn, ongeacht hun achtergrond, geslacht, vooropleiding of andere kenmerken. In dit rapport onderzoeken we of ons voorspellingsmodel, dat schat hoe waarschijnlijk het is dat een student naar het volgende jaar doorgaat, eerlijk werkt voor alle groepen studenten.

**Bias** ontstaat wanneer een systeem of model systematisch minder goed werkt voor bepaalde groepen. Dit kan onopzettelijk gebeuren, zelfs wanneer iedereen het beste voorheeft. Denk aan een arts die verschillende diagnoses stelt op basis van dezelfde symptomen, afhankelijk van het geslacht van de patiënt, dat zou medisch bezien oneerlijk zijn. Net zo onderzoeken we of ons model eerlijk is.

## Hoe werkt deze analyse?

Deze analyse bestaat uit drie stappen:

1. **We verzamelen historische data**: We kijken naar gegevens van studenten uit voorgaande jaren (geslacht, vooropleiding, behaalde cijfers, en of ze met succes naar het volgende jaar doorgingen).

2. **Een computerprogramma leert patronen**: We trainen een machine learning model (een soort statistische leermeester) die leert welke factoren samenhangen met studiesucces. Het model leert patronen uit de data.

3. **We controleren kansengelijkheid**: We vergelijken hoe goed het model voorspelt voor verschillende groepen studenten. Werkt het even goed voor mannen en vrouwen? Voor studenten met verschillende vooropleidingen? Of voorspelt het model voor sommige groepen beter of slechter?

Dit proces is vergelijkbaar met het testen van een thermometer: je wilt niet alleen weten of deze nauwkeurig is, maar ook of deze even nauwkeurig temperatuur meet voor iedereen.

Voor een gedetailleerde uitleg van de methodologie, zie [Methodologie](#methodologie). Voor uitleg van technische termen, zie [Bijlage B: Glossarium](#bijlage-b-glossarium).

\newpage

# Methodologie

De NFWA methode gebruikt machine learning als diagnostisch instrument om bias in studiedata te identificeren. We controleren of de voorspellingen van het model systematisch verschillen tussen groepen op basis van gevoelige kenmerken (geslacht, vooropleiding, aansluiting). Dit helpt ons bij het begrijpen van potentiële ongelijkheden in onderwijs en hoe we die kunnen aanpakken.

## Analysestappen

### Stap 1: Data voorbereiding en kenmerken

```{r}
#| echo: false
#| results: asis

# Load metadata if available
metadata_file <- file.path(temp_path, "analysis_metadata.rds")
if (file.exists(metadata_file)) {
  metadata <- readRDS(metadata_file)

  cat("- **Aantal studenten**: ", metadata$n_students, "\n")
  cat("- **Onderzochte uitkomst**: Retentie, ofwel 'doorgaan naar jaar 2'\n")
  cat("  - Dit betekent: Is de student succesvol geweest in het eerste jaar en gaat door naar het tweede jaar?\n")
  cat("- **Gevoelige variabelen**: ", paste(names(conclusions_list), collapse = ", "), "\n")
  cat("  - Dit zijn kenmerken waarvoor we **geen kansenongelijkheid willen** (geen ongelijke behandeling gebaseerd op deze factoren)\n\n")
} else {
  cat("- **Onderzochte uitkomst**: Retentie, ofwel 'doorgaan naar jaar 2'\n")
  cat("  - Dit betekent: Is de student succesvol geweest in het eerste jaar en gaat door naar het tweede jaar?\n")
  cat("- **Gevoelige variabelen**: De kenmerken waarvoor we **geen kansenongelijkheid willen**\n\n")
}
```

### Stap 2: Model training (het leren van patronen)

```{r}
#| echo: false
#| results: asis

metadata_file <- file.path(temp_path, "analysis_metadata.rds")
if (file.exists(metadata_file)) {
  metadata <- readRDS(metadata_file)

  cat("We trainen twee verschillende typen modellen. Om zeker te weten welke het meest betrouwbaar is voor uw studenten.:\n\n")
  cat("**1. Logistische Regressie (met LASSO regularisatie)**\n\n")
  cat("- Dit is een statistische methode die naar verbanden kijkt. Het zoekt uit welke factoren het meest belangrijk zijn voor studiesucces.\n")
  cat("- LASSO betekent dat het alleen de belangrijkste factoren behoudt (rest verwijdert)\n\n")
  cat("**2. Random Forest (1000 kleine beslisbomen)**\n\n")
  cat("- Dit model werkt als volgt: Het combineert veel kleine 'Ja/Nee'-vragen.\n")
  cat("- Iedere boom maakt zijn eigen voorspelling, dan wordt de meerderheid gekozen.\n")
  cat("- Het is vergelijkbaar met een team van experts die gezamenlijk een diagnose stellen.\n\n")
  cat("**Gekozen model voor deze analyse**: ", metadata$best_model, "\n\n")
  cat("**Model prestatie (AUC)**: ", round(metadata$model_auc, 3), "\n\n")
  cat("- AUC loopt van 0 tot 1 (hoger = beter)\n")
  cat("- 0.5 = volledig gokken\n")
  cat("- \\> 0.7 = acceptabel prestatief\n")
  cat("- 0.8+ = goed prestatief\n\n")
} else {
  cat("We trainen twee verschillende modellen en selecteren het beste:\n\n")
  cat("- **Logistische Regressie**: Statistische methode, makkelijk uit te leggen\n")
  cat("- **Random Forest**: Machine learning methode, vaak nauwkeuriger\n")
  cat("Daarna kiezen we het meest betrouwbare model.\n\n")
}
```

### Stap 3: Fairness evaluatie (controleren op kansengelijkheid)


Voor elke analyse wordt één groep als referentie (vergelijkingspunt) gekozen. De referentiegroep is gekozen als de grootste groep binnen die variabele. Bijvoorbeeld: als er meer mannen dan vrouwen zijn, worden mannen de referentiegroep.

Om bias te kunnen meten, hebben we een vergelijkingspunt nodig. We kunnen niet zeggen of een model "kansengelijk" is in absolute zin. We kunnen alleen zeggen of het even goed werkt voor verschillende groepen. Daarom vergelijken we alle andere groepen met de referentiegroep om te zien of het model even goed werkt.

**Let op:** In de resultaten tabel wordt de referentiegroep weergegeven als "NTB" (Nader Te Bepalen), omdat deze groep zelf niet op bias kan worden beoordeeld. Het is immers het vergelijkingspunt zelf. Zie ook [Bijlage A: Gedetailleerde visualisaties](#bijlage-a-gedetailleerde-visualisaties) voor een visuele weergave van hoe groepen worden vergeleken met de referentiegroep.

Voor elke gevoelige variabele meten we vier verschillende fairness-metrieken. Deze vier metrieken bieden verschillende perspectieven op kansengelijkheid We gebruiken meerdere metrieken omdat geen enkele metriek alles kan meten - samen geven zij een completer beeld:

-   **Equal Opportunity**:
    - Vraag: "Geeft het model even veel goede voorspellingen voor succesvolle studenten uit alle groepen?"
    - Voorbeeld: Voorspelt het model even goed voor mannen als voor vrouwen die daadwerkelijk doorgaan naar jaar 2?

-   **Predictive Parity**:
    - Vraag: "Zijn de voorspellingen even betrouwbaar voor alle groepen?"
    - Voorbeeld: Klopt het voorspeld succes even goed voor alle vooropleidingen?

-   **Accuracy Equality**:
    - Vraag: "Is het model even nauwkeurig voor iedereen?"
    - Voorbeeld: Maakt het model evenveel fouten bij alle groepen?

-   **Statistical Parity**:
    - Vraag: "Krijgen alle groepen gelijk veel positieve voorspellingen?"
    - Voorbeeld: Voorspelt het model succes voor dezelfde procentuele hoeveelheid van iedere groep?

Elk van deze vier metrieken wordt afzonderlijk beoordeeld tegen het 0.8-1.25 bereik. Deze range is een standaard in fairness research. Het komt voort uit gelijkheidsonderzoeken in arbeid, waar verhoudingen buiten 0.8-1.25 als aanwijzing voor ongelijke behandeling worden beschouwd.

### Stap 4: Bias beoordeling

Voor elke kansengelijkheid-metriek berekenen we een verhouding (ratio) ten opzichte van de referentiegroep:

-   Verhouding = 1.0: Model presteert gelijk voor beide groepen (kansengelijk)
-   Verhouding < 0.8: Model presteert slechter voor deze groep (negatieve bias)
    - Bijvoorbeeld: verhouding 0.8 betekent dat het model 20% slechter voorspelt voor vrouwen dan voor mannen
-   Verhouding > 1.25: Model presteert beter voor deze groep (positieve bias)
    - Bijvoorbeeld: verhouding 1.3 betekent dat het model 30% beter voorspelt voor mannen dan voor vrouwen
-   Verhouding tussen 0.8 en 1.25: Acceptabel verschil, geen significant verschil gedetecteerd


Om te bepalen of er kansongelijkheid is gebruiken we in deze analyse gebruiken een conservatieve aanpak: alleen als twee of meer van de vier kansengelijkheidsmetrieken een verhouding < 0.8 of > 1.25 hebben, bepalen we dat deze groep te maken heeft met bias ("Ja" in het resultaatoverzicht). Dit minimaliseert vals-positieve bevindingen.

Voor meer uitleg over deze termen, zie [Bijlage B: Glossarium](#bijlage-b-glossarium).

### Belangrijke overwegingen: Minimale groepsgrootte

We hanteren een minimum van 15 studenten per categorie om betrouwbare conclusies te kunnen trekken:

-   Met minder dan 15 studenten is het statistisch onbetrouwbaar (net zoals een enquête onder slechts 5 mensen niet representatief is)
-   Kleinere groepen worden wel in het rapport opgenomen, maar krijgen het label "Data laag".
-   Dit betekent niet dat er geen bias is, maar dat we het niet zeker kunnen zeggen vanwege te weinig data


\newpage

# Resultaten

```{r}
#| echo: false
#| fig-align: center
#| out.width: "85%"
#| fig-height: 3.5

# Since root.dir is set to work_dir, we can use the relative path
img_path <- file.path(params$temp_dir, "result_table.png")
knitr::include_graphics(img_path)
```

**Legenda:** N = aantal studenten \| % = percentage \| Bias = Ja/Nee/NTB (Nader Te Bepalen)

### Kleurcodes

$\providecolor{sqfill1}{HTML}{A84268}\providecolor{sqborder1}{HTML}{A9A9A9}\begingroup\setlength{\fboxsep}{1pt}\fcolorbox{sqborder1}{sqfill1}{\rule{0pt}{6pt}\rule{6pt}{0pt}}\endgroup$ Negatieve bias \| $\providecolor{sqfill2}{HTML}{9DBF9E}\providecolor{sqborder2}{HTML}{A9A9A9}\begingroup\setlength{\fboxsep}{1pt}\fcolorbox{sqborder2}{sqfill2}{\rule{0pt}{6pt}\rule{6pt}{0pt}}\endgroup$ Positieve bias \| $\providecolor{sqfill3}{HTML}{FCB97D}\providecolor{sqborder3}{HTML}{A9A9A9}\begingroup\setlength{\fboxsep}{1pt}\fcolorbox{sqborder3}{sqfill3}{\rule{0pt}{6pt}\rule{6pt}{0pt}}\endgroup$ Data laag \| $\providecolor{sqfill4}{HTML}{E5E5E5}\providecolor{sqborder4}{HTML}{A9A9A9}\begingroup\setlength{\fboxsep}{1pt}\fcolorbox{sqborder4}{sqfill4}{\rule{0pt}{6pt}\rule{6pt}{0pt}}\endgroup$ Referentie

\newpage

## Bijlage A: Gedetailleerde visualisaties

Deze bijlage bevat de fairness-metrieken en model-voorspellingsplots voor elke onderzochte variabele. Voor uitleg van de fairness-metrieken, zie [Stap 3: Fairness evaluatie](#stap-3-fairness-evaluatie-controleren-op-kansengelijkheid) in de Methodologie sectie.

1.  **Fairness-metrieken (staafdiagram)**

Dit diagram toont de verhoudingswaarden (ratio's) voor elke fairness-metriek per groep, ten opzichte van de referentiegroep:

-   **Referentiegroep**: De grootste groep binnen de variabele (bijv. mannen bij geslacht). Deze staat op de verticale zwarte lijn bij 0.0 (gelijk).

-   **X-as**: De verhouding (ratio) van de metriek voor deze groep ten opzichte van de referentiegroep

    -   Staven naar links (negatief) = model presteert slechter voor deze groep
        - Bijv. -0.2 betekent dat deze groep 20% slechter scoort (ratio 0.8)

    -   Staven naar rechts (positief) = model presteert beter voor deze groep
        - Bijv. +0.3 betekent dat deze groep 30% beter scoort (ratio 1.3)

    -   Op de zwarte lijn (0.0) = gelijk aan referentiegroep (ratio 1.0)

-   **Y-as**: De vier verschillende fairness-metrieken

-   **Gekleurde zones**: Rood (buiten ±20-25%) = Bias detected, Grijs (±20-25% bereik) = acceptabel

Opmerking: Hoewel we intern met ratio's werken (1.0 = gelijk), toont dit diagram de verschillen als percentages (0.0 = gelijk) voor betere leesbaarheid.

Zie ook de uitleg van de referentiegroep in [Stap 3: Fairness evaluatie](#stap-3-fairness-evaluatie-controleren-op-kansengelijkheid).

2.  **Model-voorspellingen (dichtheidsgrafiek)**

Dit diagram toont hoe het model voorspellingen maakt per groep:

-   **X-as**: Voorspelde kans op studiesucces (0-100%)

-   **Y-as**: Dichtheid (hoeveel studenten bij die voorspelling)

-   Wanneer krommen sterk uit elkaar liggen = model behandelt groepen verschillend

-   Overlappende krommen = kansengelijk model

-   Verschuiving naar links = lagere voorspelde kansen

\newpage

```{r}
#| echo: false
#| results: asis

temp_dir <- params$temp_dir
conclusions_list <- readRDS(file.path(temp_dir, "conclusions_list.rds"))

for (var_name in names(conclusions_list)) {
  var_title <- stringr::str_to_title(var_name)
  cat("\n## ", var_title, "\n\n")

  fairness_file <- file.path(temp_dir, paste0("fairness_plot_", var_name, ".png"))
  density_file <- file.path(temp_dir, paste0("fairness_density_", var_name, ".png"))

  if (file.exists(fairness_file)) {
    cat("![](", fairness_file, "){ width=90% }\n\n")
  }
  if (file.exists(density_file)) {
    cat("![](", density_file, "){ width=90% }\n\n")
  }
  cat("\\newpage\n\n")
}
```

\newpage

## Bijlage B: Glossarium

| Term | Omschrijving |
|---|---|
| **AUC** | Area Under the Curve - model prestatie (1.0 = perfect, 0.5 = gokken, \>0.7 = acceptabel) |
| **Bias** | Systematische verschillen in model-voorspellingen tussen groepen; wanneer een systeem bepaalde groepen benadeelt |
| **Equal Opportunity** | Model voorspelt even goed voor succesvolle studenten uit alle groepen |
| **Predictive Parity** | Positieve voorspellingen zijn even betrouwbaar over alle groepen |
| **Accuracy Equality** | Algemene nauwkeurigheid model gelijk over alle groepen |
| **Statistical Parity** | Proportie positieve voorspellingen gelijk over alle groepen |
| **Kansengelijkheidsmetriekwaarde (ratio)** | De verhouding van de metriek voor een groep ten opzichte van de referentiegroep: 1.0 = gelijk, 0.8 = 20% lager, 1.25 = 25% hoger. Waarden buiten 0.8-1.25 duiden op bias. |
| **Retentie** | Student gaat door naar tweede studiejaar; maatstaf van studiesucces |
| **Sensitieve variabele** | Persoonskenmerken waarvoor kansenongelijkheid ongewenst is (geslacht, vooropleiding, etniciteit, etc.) |
| **Machine Learning** | Computertechniek waarbij systemen automatisch patronen leren uit data zonder expliciet geprogrammeerd te worden |
| **Model** | Een wiskundige representatie van patronen in data; een "recept" om voorspellingen te maken |
| **Training** | Het proces waarbij een machine learning model leert van historische data |
| **Voorspelling** | Een schatting van toekomstige uitkomsten gebaseerd op het getrainde model |
| **Logistische Regressie** | Een statistische methode die binaire uitkomsten voorspelt (ja/nee); makkelijk uit te leggen |
| **Random Forest** | Een machine learning methode die veel kleine beslisbomen combineert; meestal nauwkeuriger maar moeilijker uit te leggen |
| **LASSO Regularisatie** | Een techniek die alleen de belangrijkste factoren behoudt en onbelangrijke verwijdert |
| **Fairness** | Kansengelijkheid; het principe dat systemen iedereen eerlijk behandelen ongeacht hun achtergrond |
| **Interpretabiliteit** | Hoe goed we kunnen begrijpen waarom een model bepaalde voorspellingen doet |
| **Cohort** | Een groep studenten die in dezelfde periode aan een opleiding zijn begonnen |
| **N** | Aantal; in dit rapport: aantal studenten in een groep |

## Bijlage C: Referenties en bronnen


**Wetenschappelijke basis:**

Bakker, T. (2024). *No Fairness without Awareness. Toegepast onderzoek naar kansengelijkheid in het hoger onderwijs.* Intreerede lectoraat Learning Technology & Analytics. https://doi.org/10.5281/zenodo.14204674

**Meer informatie:**

-   Lectoraat Learning Technology & Analytics: https://www.dehaagsehogeschool.nl/onderzoek/kenniscentra/no-fairness-without-awareness
-   NFWA R package repository: https://github.com/cedanl/no-fairness-without-awareness

**Contact:**

Voor vragen over deze analyse kunt u contact opnemen met:

Lectoraat Learning Technology & Analytics De Haagse Hogeschool Web: http://www.hhs.nl


## Bijlage D: Technische details


```{r}
#| echo: false
#| results: asis

# Load and display technical metadata if available
metadata_file <- file.path(temp_path, "analysis_metadata.rds")
if (file.exists(metadata_file)) {
  metadata <- readRDS(metadata_file)

  cat("**Analyse-parameters:**\n\n")
  cat("- Datum analyse:", format(Sys.Date(), "%d-%m-%Y"), "\n")
  cat("- Aantal studenten:", metadata$n_students, "\n")
  cat("- Gekozen model:", metadata$best_model, "\n")
  cat("- Model AUC:", round(metadata$model_auc, 4), "\n")
  cat("- Bias detectie-bereik: ratio < 0.8 of > 1.25\n")
  cat("- Onderzochte variabelen:", paste(names(conclusions_list), collapse = ", "), "\n")
  cat("- R package versie: nfwa", as.character(packageVersion("nfwa")), "\n")

  # Display EOI if available from metadata
  if (!is.null(metadata$eoi)) {
    cat("- Eerste jaar aan deze opleiding/instelling (EOI):", metadata$eoi, "\n")
  }
} else {
  cat("**Analyse-parameters:**\n\n")
  cat("- Datum analyse:", format(Sys.Date(), "%d-%m-%Y"), "\n")
  cat("- Onderzochte variabelen:", paste(names(conclusions_list), collapse = ", "), "\n")
  cat("- R package versie: nfwa", as.character(packageVersion("nfwa")), "\n")
}
```
